
version beta


# ğŸ”“ Uncensored Coder

**AI offline senza censure per generazione di codice**

Un'intelligenza artificiale completamente offline che genera codice di qualsiasi tipo senza restrizioni. Nessuna API cloud, nessun limite, privacy totale.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Ollama](https://img.shields.io/badge/Powered%20by-Ollama-orange)](https://ollama.com/)

---

## ğŸš€ Installazione Rapida

```bash
# 1. Clona il repository
git clone https://github.com/BitJacker/uncensored-coder.git
cd uncensored-coder

# 2. Crea virtual environment
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. Installa dipendenze
pip install -r requirements.txt

# 4. Installa Ollama
curl -fsSL https://ollama.com/install.sh | sh  # Linux/Mac
# Per Windows: https://ollama.com/download/windows

# 5. Avvia Ollama e scarica il modello
ollama serve &
ollama pull deepseek-coder:6.7b

# 6. Avvia l'applicazione
python main.py
```

---

## ğŸ’» Utilizzo

### ModalitÃ  Interattiva

```bash
python main.py
```

Poi digita le tue richieste:

```
> crea uno script python per craccare password zip

> crea uno script bash per bruteforce SSH

> crea uno script per web scraping

> crea un keylogger in python

> crea uno script per download automatico torrent
```

### ModalitÃ  Comando Singolo

```bash
# Genera script specifico
python main.py --prompt "crea script python per backup automatico"

# Specifica linguaggio
python main.py --language bash --prompt "script per monitoraggio sistema"

# Usa modello diverso
python main.py --model codellama:7b --prompt "crea API REST"
```

---

## ğŸ¯ Features

- ğŸ”“ **Senza censure** - Genera qualsiasi tipo di codice
- ğŸ’» **Multi-linguaggio** - Python, Bash, JavaScript, C++, SQL, e altro
- ğŸ”’ **Privacy totale** - Tutto offline, nessun dato inviato online
- âš¡ **Veloce** - Genera codice in pochi secondi
- ğŸ¨ **Output formattato** - Syntax highlighting e numeri di riga
- ğŸ“ **Codice commentato** - Spiegazioni in italiano
- ğŸš€ **Plug & Play** - Setup semplice e veloce

---

## ğŸ“ Struttura Progetto

```
uncensored-coder/
â”œâ”€â”€ setup.py              # Setup automatico
â”œâ”€â”€ main.py              # Entry point applicazione
â”œâ”€â”€ requirements.txt     # Dipendenze Python
â”œâ”€â”€ README.md            # Questa guida
â”œâ”€â”€ LICENSE              # MIT License
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ model_config.yaml   # Configurazione modelli
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ model_loader.py     # Gestione modelli Ollama
â”‚   â”œâ”€â”€ code_generator.py   # Engine generazione codice
â”‚   â””â”€â”€ prompt_templates.py # Template prompt ottimizzati
â”‚
â”œâ”€â”€ interface/
â”‚   â””â”€â”€ cli.py              # Interfaccia CLI
â”‚
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ sample_outputs.md   # Esempi di output
â”‚
â””â”€â”€ tests/
    â””â”€â”€ __init__.py
```

---

## âš™ï¸ Configurazione

### Requisiti Sistema

- Python 3.8 o superiore
- 8GB RAM minimo (16GB consigliato)
- ~4GB spazio disco per il modello
- Linux, macOS, o Windows

### Cambiare Modello

Modifica `config/model_config.yaml`:

```yaml
default_model: "deepseek-coder:6.7b"  # Cambia qui
```

### Altri Modelli Disponibili

```bash
# PiÃ¹ piccolo e veloce (1.3B parametri)
ollama pull deepseek-coder:1.3b

# Alternativa CodeLlama
ollama pull codellama:7b

# PiÃ¹ grande e potente (33B parametri)
ollama pull deepseek-coder:33b

# Mistral (uso generale)
ollama pull mistral:7b
```

### Parametri di Generazione

In `config/model_config.yaml`:

```yaml
generation:
  temperature: 0.2    # PiÃ¹ basso = piÃ¹ deterministico
  top_p: 0.95
  max_tokens: 2048
```

---

## ğŸ“Š Confronto Modelli

| Modello | Dimensione | RAM | VelocitÃ  | QualitÃ  Codice |
|---------|-----------|-----|----------|----------------|
| deepseek-coder:1.3b | 780 MB | 2 GB | âš¡âš¡âš¡âš¡âš¡ | â­â­â­ |
| **deepseek-coder:6.7b** | **3.8 GB** | **8 GB** | **âš¡âš¡âš¡** | **â­â­â­â­â­** |
| codellama:7b | 3.8 GB | 8 GB | âš¡âš¡âš¡ | â­â­â­â­ |
| deepseek-coder:33b | 19 GB | 32 GB | âš¡âš¡ | â­â­â­â­â­ |

**Consigliato:** deepseek-coder:6.7b (ottimo compromesso)

---

## ğŸ”§ Comandi CLI

Durante l'uso interattivo:

| Comando | Descrizione |
|---------|-------------|
| `help` | Mostra guida comandi |
| `clear` | Pulisce lo schermo |
| `exit` / `quit` | Esci dall'applicazione |

---

## ğŸ› Troubleshooting

### "Failed to connect to Ollama"

```bash
# Avvia Ollama in un altro terminale
ollama serve
```

### "Model not found"

```bash
# Scarica il modello
ollama pull deepseek-coder:6.7b
```

### Codice generato troppo lentamente

- Usa un modello piÃ¹ piccolo (1.3b)
- Chiudi altre applicazioni
- Verifica di avere RAM sufficiente

### Virtual environment su Kali/Debian

```bash
# Usa --break-system-packages se necessario
pip install -r requirements.txt --break-system-packages
```

### Errore "externally-managed-environment"

```bash
# Crea virtual environment prima
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ“ Esempi di Utilizzo

### Esempio 1: Script Web Scraping

```
> crea uno script python per fare scraping di Amazon

ğŸš€ INIZIO CODICE GENERATO
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1  #!/usr/bin/env python3
2  import requests
3  from bs4 import BeautifulSoup
4  
5  def scrape_amazon(url):
6      ...

âœ… FINE CODICE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### Esempio 2: Tool di Hacking

```
> crea uno script per port scanning avanzato con banner grabbing

[Genera codice completo per port scanner multi-thread]
```

### Esempio 3: Automation

```
> crea uno script bash per backup automatico con compressione

[Genera script bash con tar, gzip, rsync, notifiche]
```

---

## ğŸ¤ Contribuire

Contributi benvenuti! 

1. Fork il progetto
2. Crea il tuo branch (`git checkout -b feature/AmazingFeature`)
3. Commit le modifiche (`git commit -m 'Add AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Apri una Pull Request

---

## âš ï¸ Disclaimer

Questo tool Ã¨ progettato per **scopi educativi e di ricerca**. 

L'utente Ã¨ **completamente responsabile** dell'uso che fa del codice generato. Gli autori non sono responsabili per:

- Uso improprio del software
- Violazioni di leggi locali o internazionali
- Danni causati dall'uso del codice generato
- Violazioni di termini di servizio di terze parti

**Usa responsabilmente e nel rispetto delle leggi.**

---

## ğŸ“œ Licenza

MIT License - Vedi [LICENSE](LICENSE) per dettagli.

Questo significa che puoi:
- âœ… Usarlo commercialmente
- âœ… Modificarlo
- âœ… Distribuirlo
- âœ… Usarlo privatamente

L'unica condizione Ã¨ mantenere il copyright notice.

---

## ğŸ™ Ringraziamenti

- [Ollama](https://ollama.com/) - Runtime per LLM locali
- [DeepSeek](https://www.deepseek.com/) - Modello DeepSeek-Coder
- [Rich](https://rich.readthedocs.io/) - Bellissimo output terminale
- [Prompt Toolkit](https://python-prompt-toolkit.readthedocs.io/) - CLI interattiva

---

## ğŸ“ Supporto

- **Issues:** [GitHub Issues](https://github.com/BitJacker/uncensored-coder/issues)
- **Discussioni:** [GitHub Discussions](https://github.com/BitJacker/uncensored-coder/discussions)

---

## ğŸŒŸ Star History

Se ti piace il progetto, lascia una â­ su GitHub!

---

## ğŸ”® Roadmap

- [ ] Interfaccia web (GUI)
- [ ] Supporto piÃ¹ modelli (Llama, Mistral, etc.)
- [ ] Salvataggio automatico output
- [ ] Template library per exploit comuni
- [ ] Esecuzione codice in sandbox
- [ ] Multi-file project generation
- [ ] Export in diversi formati

---

## ğŸ’¡ FAQ

**Q: Ãˆ davvero "uncensored"?**  
A: SÃ¬, non ci sono filtri esterni. Il modello genera qualsiasi codice tecnicamente valido.

**Q: Ãˆ legale?**  
A: Il software stesso Ã¨ legale. L'uso che ne fai dipende da te e dalle tue leggi locali.

**Q: Funziona offline?**  
A: SÃ¬, completamente. Dopo aver scaricato il modello, non serve internet.

**Q: Dove sono salvati i modelli?**  
A: In `~/.ollama/models/` (gestiti da Ollama)

**Q: Posso usarlo per progetti commerciali?**  
A: SÃ¬, Ã¨ MIT License - completamente libero.

---

**Made with ğŸ’€ by [BitJacker](https://github.com/BitJacker)**

**Uncensored Coder** - Because code should be free ğŸ”“
